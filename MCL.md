# MCL (Monte Carlo Localization)

Monte Carlo Localization (MCL) is a probabilistic algorithm used for robot localization. It uses a set of particles to represent the possible positions of the robot in the environment. Each particle has a weight that represents the likelihood of the robot being at that position.

## Overview

In MCL, the robot's position is not a single point. Instead, you keep track of many (hundreds or thousands) of possible positions, called particles. Each particle has an `x`, and `y` coordinate, as well as a weight that indicates how likely it is that the robot is actually at that position.

Note that in most MCL use cases, you also track the robot's orientation (`theta`). However, because the VEX V5 IMU's heading is so much more accurate than general VEX odometry, orientation can be safely ignored for the purposes of localization.

MCL can be broken down into 5 key steps:

1. **Initialization**: This step runs once at the beginning of the algorithm. Subsequent steps run in an infinite loop tied to your odometry. A set of particles is randomly distributed based on where you think the robot already is. Generally, at the start of the autonomous period or autonomous skills, you have a pretty good idea of exactly where the robot is, so you can initialize the particles in a small area around that position.

2. **Prediction**: As the robot moves, each particle's position is updated based on what the odometry thinks the robot has done. Additionally, however, random noise is added to each particle to account for uncertainty in the odometry.

3. **Update**: The robot uses measurements from the distance sensors on the robot to update the weights of each particle. Generally, particles with predicted sensor readings that more closely match the actual sensor readings get higher weights. Then, all the weights are normalized so that they sum to 1.

4. **Estimation**: The robot's estimated position is calculated as the weighted average of all the particles' positions. This gives a single best guess of where the robot is based on the distribution of particles.

5. **Resampling**: A new set of particles is generated by randomly sampling from the existing particles, with the probability of selecting each particle being proportional to its weight. This means that particles with higher weights are more likely to be selected, while particles with low weights may be discarded.

## A Note on Optimization

One of the biggest challenges with writing good MCL is code optimization. Generally, with MCL, the more particles you have, the better your localization will be. However, the VEX V5 Brain isn't particularly performant, so your code needs to be as optimized as possible. More specifically, you need to reduce the number of operations you do **per particle** (or inside a loop over particles) as possible. While the code presented in this guide is not perfectly optimized, it is quite fast and can handle about 5000 particles in 10ms on the Brain.

An easy way to optimize code like this is to limit division. Division is usually 5-10 times slower than multiplication, so oftentimes, instead of dividing by `x`, we precomute `1/x` and multiply by that instead.

## Implementation

Finally, some actual code!

### Step -2: Prerequisites

You need a simple `Point` struct to represent points, with operator overloading for convenience. Some libraries/templates may already have this.

### Step -1: Randomization

In this demo, I use the XorShift32 random number generator. This is a very fast PRNG implementation that is great for MCL. While it's not cryptographically secure, it's great for generating random numbers in this context.

Here's my XorShift32 implementation:

```rust
#[derive(Clone, Copy)]
pub struct XorShift32 {
  state: u32,
}

impl XorShift32 {
  #[inline(always)]
  pub const fn new(seed: u32) -> Self {
    Self {
      state: if seed == 0 {
        0x12345678
      } else {
        seed
      },
    }
  }

  #[inline(always)]
  pub fn next_u32(&mut self) -> u32 {
    let mut x = self.state;
    x ^= x << 13;
    x ^= x >> 17;
    x ^= x << 5;
    self.state = x;
    x
  }

  #[inline(always)]
  pub fn f32(&mut self) -> f32 {
    (self.next_u32() >> 8) as f32 * (1.0 / (1u32 << 24) as f32)
  }

  #[inline(always)]
  pub fn range_f32(&mut self, min: f32, max: f32) -> f32 {
    min + (max - min) * self.f32()
  }

  // box-muller transform, use ziggurat for optimization if you want
  #[inline(always)]
  pub fn gaussian(&mut self, std_dev: f32) -> f32 {
    let u1 = self.f32().max(1e-12);
    let u2 = self.f32();
    let r = (-2.0 * u1.ln()).sqrt();
    let theta = f32::consts::TAU * u2;
    r * theta.cos() * std_dev
  }
}

// rust specific default implementation

impl Default for XorShift32 {
  fn default() -> Self {
    Self::new(unsafe { vex_sdk::vexSystemPowerupTimeGet() } as u32)
  }
}
```

### Step 0: Setup

First, we need some basic constants about the VEX Competition field:

```rust
// Official VEX Competition Field size in inches
const FIELD_SIZE: f32 = 140.42;
const HALF_SIZE: f32 = 0.5 * FIELD_SIZE;
const FIELD_MIN: f32 = -HALF_SIZE;
const FIELD_MAX: f32 = HALF_SIZE;
```

For performance reasons, the MCL implementation here uses a SoA (Structure of Arrays) approach rather than a vector/array of structs approach.

The MCL struct is quite simple: We need arrays for the `x`, `y`, and `weight` of each particle. The struct itself takes in a constant generic parameter `N`, which is the number of particles to use. This way, instead of using a vector (which would require heap allocation and indirection), we can use fixed-size arrays allocated on the stack.

We also need a temporary set of arrays for resampling (you'll see why later), and the presampling arrays are used to store the state of the particles before resampling for debugging/logging purposes (more on this later).

```rust
pub struct MCL<const N: usize> {
  pub particle_x: [f32; N],
  pub particle_y: [f32; N],
  pub particle_weights: [f32; N],

  pub temp_x: [f32; N],
  pub temp_y: [f32; N],
  pub temp_weights: [f32; N],

  pub presample_x: [f32; N],
  pub presample_y: [f32; N],
  pub presample_weights: [f32; N],

  rng: XorShift32,
}
```

Note that in C++, the fixed-size array implementation would look something like this:

```cpp
template <size_t N>
struct MCL {
  float particle_x[N];
  float particle_y[N];
  float particle_weights[N];
  // etc
};
```

If you happen to be using rust as well, you'll need a default implementation for MCL to initialize the arrays:

```rust
impl<const N: usize> Default for MCL<N> {
  fn default() -> Self {
    Self {
      particle_x: [0.0; N],
      particle_y: [0.0; N],
      particle_weights: [1.0 / N as f32; N],

      temp_x: [0.0; N],
      temp_y: [0.0; N],
      temp_weights: [0.0; N],

      rng: XorShift32::default(),

      presample_x: [0.0; N],
      presample_y: [0.0; N],
      presample_weights: [0.0; N],
    }
  }
}
```

We'll also need to be able to capture the data about a distance sensor reading. The following struct captures a single sensor's actual reading, as well as information on its variance, relative position to the robot at a given heading, and a second point in the direction of the sensor's heading (used for raycasting later).

```rust
#[derive(Clone, Copy)]
pub struct Reading {
  pub recorded: f32,
  pub inv_var: f32,

  pub relative_pos: Point,
  pub proj_relative: Point,
}

impl Reading {
  pub fn new(recorded: f32, std_dev: f32, relative_pos: Point, proj_relative: Point) -> Self {
    Self {
      recorded,
      inv_var: -0.5 / (std_dev * std_dev),
      relative_pos,
      proj_relative,
    }
  }
}
```

Note that we save the inverse variance multiplied by -0.5 to optimize the weight calculation later.

### Step 1: Initialization

Whenever you set the robot's position programatically, such as at the start of an autonomous routine, you should initialize the MCL particles around that position.

Additionally, you should seed your RNG based on the current system time to ensure a good random distribution.

```rust
pub fn init(&mut self, x: f32, y: f32, spread: f32) {
	self.rng = XorShift32::new(unsafe { vex_sdk::vexSystemPowerupTimeGet() } as u32);

  for i in 0..N {
    self.particle_x[i] = (x + self.rng.range_f32(-spread, spread)).clamp(FIELD_MIN, FIELD_MAX);
    self.particle_y[i] = (y + self.rng.range_f32(-spread, spread)).clamp(FIELD_MIN, FIELD_MAX);
    self.particle_weights[i] = 1.0 / N as f32;
  }
}
```

A good value for spread is about 2 or 3 inches, because generally, you have a pretty good idea of where the bot starts of the field.

The C++ equivalent of

```rust
unsafe { vex_sdk::vexSystemPowerupTimeGet() }
```

is

```cpp
pros::micros()
```

### Step 2: Prediction

Your odometry should be updating in a loop in your code, based on information from your motor encoders, IMU, and possible a odometry tracking wheel setup. After updating your odometry, you should call this prediction step (and the other following steps) to update your MCL particles. More information on using this MCL will come later.

There are two components to the prediction step: moving the particles based on odometry, and adding random noise to each particle.

```rust
/// step each particle but add some randomization as well
pub fn predict(&mut self, dx: f32, dy: f32, std_dev: f32) {
  for i in 0..N {
    self.particle_x[i] += dx + self.rng.gaussian(std_dev);
    self.particle_y[i] += dy + self.rng.gaussian(std_dev);
    self.particle_x[i] = self.particle_x[i].clamp(FIELD_MIN, FIELD_MAX);
    self.particle_y[i] = self.particle_y[i].clamp(FIELD_MIN, FIELD_MAX);
  }
}
```

In this function, `dx` and `dy` are the changes in position according to your odometry since the last update. `std_dev` is the standard deviation of the noise to add to each particle. A good approximation for this will be found later.

### Step 3: Update

This is the core part of MCL. This step uses the distance sensor readings to update the weights of each particle.

First, however, we need to be able to predict what a distance sensor would read if the robot were at a given particle's position. This is done using raycasting. Because the field is a square, we can highly optimize the raycasting process.

We can define a `Line` to be a directed line segment from one point to another:

```rust
pub struct Line {
  pub start: Point,
  pub end: Point,
}
```

For the distance sensor raycasting, we can treat a Line as an infinite ray starting at `start` and going through `end` instead of a line segment. This allows us to highly optimize the calculation of the intersection point between the ray and the field boundaries.

I won't get into the nitty gritty of exactly how this function works, but the key is that it returns the distance from the start of the ray to the intersection point with the field boundary. If there is no intersection, it returns `None`. In C++, you could use std::optional or just return -1.0 to indicate no intersection.

```rust
impl Line {
  /// assumes line segments are actually rays
  #[inline(always)]
  pub fn square_intersect_distance(&self, center_x: f32, center_y: f32, width: f32, height: f32) -> Option<f32> {
    let half_width = width * 0.5;
    let half_height = height * 0.5;

    let rel_start_x = self.start.x - center_x;
    let rel_start_y = self.start.y - center_y;

    let dx = self.end.x - self.start.x;
    let dy = self.end.y - self.start.y;

    let mut best_t = f32::INFINITY;

    // check x sides
    if dx.abs() > 1e-6 {
      let inv_dx = 1.0 / dx;
      let target_x = if dx > 0.0 {
        half_width
      } else {
        -half_width
      };
      let t = (target_x - rel_start_x) * inv_dx;

      if t >= 0.0 {
        let y = rel_start_y + t * dy;
        if y.abs() <= half_height {
          best_t = t;
        }
      }
    }

    // check y sides
    if dy.abs() > 1e-6 {
      let inv_dy = 1.0 / dy;
      let target_y = if dy > 0.0 {
        half_height
      } else {
        -half_height
      };
      let t = (target_y - rel_start_y) * inv_dy;

      if t >= 0.0 && t < best_t {
        let x = rel_start_x + t * dx;
        if x.abs() <= half_width {
          best_t = t;
        }
      }
    }

    if best_t < f32::INFINITY {
      Some(best_t * dx.hypot(dy))
    } else {
      None
    }
  }
}
```

We can now add the following function to the `Reading` struct to predict what the distance sensor would read if the robot were at a given particle's position:

```rust
impl Reading {
  #[inline(always)]
  pub fn predict(&self, particle_pos: Point) -> Option<f32> {
    Line::new(self.relative_pos + particle_pos, self.proj_relative + particle_pos).square_intersect_distance(
      0.0,
      0.0,
      constants::FIELD_SIZE,
      constants::FIELD_SIZE,
    )
  }
}
```

Now that we have the raycasting set up, we can implement the update step.

Here's our function header:

```rust
pub fn update(&mut self, readings: Vec<Reading>) {
  let mut max_weight = 0.0f32;
```

The first step is to loop over every particle and caluclate its weight. We start with a weight of 1.0 for each particle:

```rust
for i in 0..N {
  let mut weight = 1.0f32;
```

Then, for each distance sensor reading:

```rust
for reading in readings.iter() {
```

We need to predict what the sensor would read if the robot were at this particle's position. If there is no intersection, we can set the weight to 0 and break out of the loop early.

```rust
if let Some(predicted) = reading.predict(Point {
  x: self.particle_x[i],
  y: self.particle_y[i],
}) {
  // calculate weight
} else {
  weight = 0.0;
  break;
}
```

To actually calculate the weight, we use the following formula:

```
error = recorded - predicted
w = e^(inv_var * error^2)
```

Where `recorded` is the actual distance sensor reading, `predicted` is the predicted reading for this particle, and `inv_var` is the inverse variance multiplied by -0.5 that we precomputed earlier.

This becomes:

```rust
let error = reading.recorded - predicted;
weight *= (reading.inv_var * error * error).exp();
if weight == 0.0 {
  break;
}
```

After weighting the particle, we do some final checks:

```rust
if !weight.is_finite() || weight < 0.0 {
  weight = 0.0;
}

self.particle_weights[i] = weight;
if weight > max_weight {
  max_weight = weight;
}
```

If you've been following along, you should have something akin to this (in the language you are using):

```rust
pub fn update(&mut self, readings: Vec<Reading>) {
  let mut max_weight = 0.0f32;

  // weight each particle
  for i in 0..N {
    let mut weight = 1.0f32;

    for reading in readings.iter() {
      if let Some(predicted) = reading.predict(Point {
        x: self.particle_x[i],
        y: self.particle_y[i],
      }) {
        let error = reading.recorded - predicted;
        weight *= (reading.inv_var * error * error).exp();
        if weight == 0.0 {
          break;
        }
      } else {
        weight = 0.0;
        break;
      }
    }

    if !weight.is_finite() || weight < 0.0 {
      weight = 0.0;
    }

    self.particle_weights[i] = weight;
    if weight > max_weight {
      max_weight = weight;
    }
  }
```

Lastly, we make sure we have weights that sum to 1.0 and then normalize them:

```rust
  if max_weight <= 0.0 {
    // reset weights if all zero
    let uniform_weight = 1.0 / N as f32;
    for i in 0..N {
      self.particle_weights[i] = uniform_weight;
    }

    return;
  }

  let mut weight_sum = 0.0f32;
  for i in 0..N {
    self.particle_weights[i] /= max_weight;
    weight_sum += self.particle_weights[i];
  }

  if weight_sum <= 0.0 {
    // reset weights if all zero
    let uniform_weight = 1.0 / N as f32;
    for i in 0..N {
      self.particle_weights[i] = uniform_weight;
    }

    return;
  }

  let inv_weight_sum = 1.0 / weight_sum;
  for i in 0..N {
    self.particle_weights[i] *= inv_weight_sum;
  }
}
```

### Step 4: Estimation

To get the estimated position of the robot, we simply calculate the weighted average of all the particles' positions:

```rust
pub fn estimate(&self) -> Point {
  let mut est_x = 0.0f32;
  let mut est_y = 0.0f32;

  for i in 0..N {
    est_x += self.particle_x[i] * self.particle_weights[i];
    est_y += self.particle_y[i] * self.particle_weights[i];
  }

  Point {
    x: est_x,
    y: est_y,
  }
}
```

### Step 5: Resampling

For resampling, we use a highly perfomant systematic sampling implementation.

To start, we save the current weights and positions of the particles for debugging/logging purposes:

```rust
pub fn resample(&mut self) {
  self.presample_x.copy_from_slice(&self.particle_x);
  self.presample_y.copy_from_slice(&self.particle_y);
  self.presample_weights.copy_from_slice(&self.particle_weights);
```

Our goal is to divide the range [0.0, 1.0] into N segments, where each segment corresponds to a particle and its weight. A higher weight means a larger segment. Think of it like making each particle a "bucket", and the size of the bucket is proportional to its weight.

We precalulate the reciprocal of N for optimization, and an initial random offset:

```rust
let inv_n = 1.0 / N as f32;
let offset = self.rng.f32() * inv_n;
```

We also need to keep track of the cumulative weight at the current index:

```rust
let mut cumulative_weight = self.particle_weights[0];
let mut idx = 0;
```

For every particle;

```rust
for i in 0..N {
```

Inside the loop, our goal is to drop a "pin" at intervals of `inv_n`, starting from `uniform_offset`, and see which particle's bucket it falls into. This means that particles with larger weights (bigger buckets) will have more "pins falling into them". In other words, they are more likely to be selected (possibly multiple times).

We first calculate the position of our sample:

```rust
let sample = offset + (i as f32) * inv_n;
```

We then find the index of the particle whose cumulative weight is just greater than or equal to our sample. This is done using a simple linear search:

```rust
while sample > cumulative_weight && idx < N - 1 {
	idx += 1;
	cumulative_weight += self.particle_weights[idx];
}
```

However, note that idx is NOT reset for each iteration of the outer loop. This means that our sampling is O(N) instead of O(N^2), because we only move forward through the cumulative weights array.

Finally, we assign the selected particle's position and new weight (which is just 1/N, because each particle is equally likely after resampling) to the temporary arrays:

```rust
self.temp_x[i] = self.particle_x[idx.min(N - 1)];
self.temp_y[i] = self.particle_y[idx.min(N - 1)];
self.temp_weights[i] = inv_n;
```

Outside of the loop, we copy the temporary arrays back to the main particle arrays:

```rust
self.particle_x.copy_from_slice(&self.temp_x);
self.particle_y.copy_from_slice(&self.temp_y);
self.particle_weights.copy_from_slice(&self.temp_weights);
```

The full resampling function now looks like this:

```rust
pub fn resample(&mut self) {
	self.presample_x.copy_from_slice(&self.particle_x);
	self.presample_y.copy_from_slice(&self.particle_y);
	self.presample_weights.copy_from_slice(&self.particle_weights);

	let inv_n = 1.0 / N as f32;

	let offset = self.rng.f32() * inv_n;

	let mut cumulative_weight = self.particle_weights[0];
	let mut idx = 0;

	for i in 0..N {
		let sample = offset + (i as f32) * inv_n;

		while sample > cumulative_weight && idx < N - 1 {
			idx += 1;
			cumulative_weight += self.particle_weights[idx];
		}

		self.temp_x[i] = self.particle_x[idx];
		self.temp_y[i] = self.particle_y[idx];
		self.temp_weights[i] = inv_n;
	}

	self.particle_x.copy_from_slice(&self.temp_x);
	self.particle_y.copy_from_slice(&self.temp_y);
	self.particle_weights.copy_from_slice(&self.temp_weights);
}
```

## Usage

Now, the question is: how do I actually use this MCL effectively?

We need to call the four main steps (prediction, update, resample, estimate) in a loop immediately after your odometry updates.

Below is one way to implement this. Note that `dx` and `dy` are the changes in the robot's position according to your odometry since the last update.

### Step 1: Prediction

A good estimate for the standard deviation of the odometry updates is the hypotenuse of dy and dx divided by 4.0. The reasoning for this is beyond the scope of this guide, but generally, the more the robot moves, the less accurate the odometry is likely to be.

Additionally, **you may need to tune this value based on your robot and testing results.**

```rust
mcl.predict(dx, dy, dx.hypot(dy) / 4.0);
```

### Step 2: Get and process distance sensor readings:

This code will vary greatly based on how you handle distance sensors in your codebase. However, there are several general steps to follow:

1. Get the actual distance sensor readings from your sensors.
2. Filter the distance sensor readings. You can filter based on object size, distance, and of course drop sensors that don't have a valid reading. You can also check if the sensors are pointing at a match loader or goal (using the same method for checking the distance from the sensor to the wall), and drop those readings as well.
3. For each valid reading, create a `Reading` struct. You'll need to know the relative position of each sensor to the robot's center of rotation. Rotate each sensor's relative position using `x = x * cos(robot_theta)` and `y = y * sin(robot_theta)`. You'll also need to create a second point in the direction of the sensor's heading for raycasting. This will be at the relative position plus `(cos(sensor_theta + robot_theta), sin(sensor_theta + robot_theta))`.

Finally, to calculate the sensor's standard deviation, we use the information given from the VEX website:

> Below 200mm the accuracy is approximately +/‚Äê15mm, above 200mm the accuracy is approximately 5%.

This "accuracy" refers to 3 standard devations, so to get the standard deviation, we can use the following formula (which has been converted to inches):

```rust
// d is in inches here
let d = sensor.get_distance();
let bound = if d < 7.874015 {
	0.590551f32
} else {
	0.05_f32 * d
};

const K: f32 = 3.0;
let std_dev = (bound / K).max(1e-6_f32);
```

This gives you the information you need to construct a `Reading` struct for each valid distance sensor reading.

# Step 2.5: Update

Now that you have a vector of `Reading` structs, you can call the update step:

```rust
mcl.update(readings);
```

### Step 3: Estimate

Finally, you can get the estimated position of the robot and update your robot's position accordingly:

```rust
let estimated_pos = mcl.estimate();
robot.pos.x = estimated_pos.x;
robot.pos.y = estimated_pos.y;
```

### Step 4: Resample

After updating the weights, you can resample the particles:

```rust
mcl.resample();
```

## Debugging and Tuning

For MCL to work effectively, you need to tune it properly. The best way to do this is to log the particle positions right before the resampling step onto an SD card and then visualize the point on your computer.

A couple notes on implementing this on the VEX V5 Brain side:

- Use 'append' mode when writing to the SD card: don't try and store the whole log in memory, or you will quickly run out of RAM.
- JSON or CSV are good formats for logging data.
- Read the `presample_x`, `presample_y`, and `presample_weights` arrays to get the particle data before resampling.
- Log the estimated position as well for reference and plotting.

Generally, if the particles aren't converging within the bounds of your robot relatively quickly, you might want to reduce odometry noise in the prediction step.
