# MCL (Monte Carlo Localization)

Monte Carlo Localization (MCL) is a probabilistic algorithm used for robot localization. It uses a set of particles to represent the possible positions of the robot in the environment. Each particle has a weight that represents the likelihood of the robot being at that position.

## Overview

In MCL, the robot's position is not a single point. Instead, you keep track of many (hundreds or thousands) of possible positions, called particles. Each particle has an `x`, and `y` coordinate, as well as a weight that indicates how likely it is that the robot is actually at that position.

Note that in most MCL use cases, you also track the robot's orientation (`theta`). However, because the VEX V5 IMU's heading is so much more accurate than general VEX odometry, orientation can be safely ignored for the purposes of localization.

MCL can be broken down into 5 key steps:

1. **Initialization**: This step runs once at the beginning of the algorithm. Subsequent steps run in an infinite loop tied to your odometry. A set of particles is randomly distributed based on where you think the robot already is. Generally, at the start of the autonomous period or autonomous skills, you have a pretty good idea of exactly where the robot is, so you can initialize the particles in a small area around that position.

2. **Prediction**: As the robot moves, each particle's position is updated based on what the odometry thinks the robot has done. Additionally, however, random noise is added to each particle to account for uncertainty in the odometry.

3. **Update**: The robot uses measurements from the distance sensors on the robot to update the weights of each particle. Generally, particles with predicted sensor readings that more closely match the actual sensor readings get higher weights. Then, all the weights are normalized so that they sum to 1.

4. **Estimation**: The robot's estimated position is calculated as the weighted average of all the particles' positions. This gives a single best guess of where the robot is based on the distribution of particles.

5. **Resampling**: A new set of particles is generated by randomly sampling from the existing particles, with the probability of selecting each particle being proportional to its weight. This means that particles with higher weights are more likely to be selected, while particles with low weights may be discarded.

## A Note on Optimization

One of the biggest challenges with writing good MCL is code optimization. Generally, with MCL, the more particles you have, the better your localization will be. However, the VEX V5 Brain isn't particularly performant, so your code needs to be as optimized as possible. More specifically, you need to reduce the number of operations you do **per particle** (or inside a loop over particles) as possible. While the code presented in this guide is not perfectly optimized, it is quite fast and can handle about 5000 particles in 10ms on the Brain.

An easy way to optimize code like this is to limit division. Division is usually 5-10 times slower than multiplication, so oftentimes, instead of dividing by `x`, we precomute `1/x` and multiply by that instead.

## Implementation

Finally, some actual code!

### Step -2: Prerequisites

Some prerequisite structs (`Point`, `Position`, and `Rotation`) and their associated methods and operator overloads are defined in `Prerequisites.md`. You can use those directly, or implement your own versions in your codebase.

### Step -1: Randomization

In this demo, I use the XorShift32 random number generator. This is a very fast PRNG implementation that is great for MCL. While it's not cryptographically secure, it's great for generating random numbers in this context.

Here's my XorShift32 implementation:

---

```cpp
struct XorShift32 {
  uint32_t state;

  inline XorShift32(uint32_t seed = pros::micros())
    : state(seed == 0 ? 0x12345678 : seed) {}

  inline uint32_t next_u32() {
    uint32_t x = state;
    x ^= x << 13;
    x ^= x >> 17;
    x ^= x << 5;
    state = x;
    return x;
  }

  inline float next_f32() {
    return (next_u32() >> 8) * (1.0f / (1u << 24));
  }

  inline float range_f32(float min, float max) {
    return min + (max - min) * next_f32();
  }

  // box-muller transform, use ziggurat for optimization if you want
  inline float gaussian(float std_dev) {
    float u1 = std::max(next_f32(), 1e-12f);
    float u2 = next_f32();
    float r = std::sqrt(-2.0f * std::log(u1));
    float theta = 2.0f * M_PI * u2;
    return r * std::cos(theta) * std_dev;
  }
};
```

### Step 0: Setup

First, we need some basic constants about the VEX Competition field:

```cpp
// Official VEX Competition Field size in inches
const float FIELD_SIZE = 140.42f;
const float HALF_SIZE = 0.5f * FIELD_SIZE;
const float FIELD_MIN = -HALF_SIZE;
const float FIELD_MAX = HALF_SIZE;
```

For performance reasons, the MCL implementation here uses a SoA (Structure of Arrays) approach rather than a vector/array of structs approach.

The MCL struct is quite simple: We need arrays for the `x`, `y`, and `weight` of each particle. The struct itself takes in a constant generic parameter `N`, which is the number of particles to use. This way, instead of using a vector (which would require heap allocation and indirection), we can use fixed-size arrays allocated on the stack.

We also need a temporary set of arrays for resampling (you'll see why later), and the presampling arrays are used to store the state of the particles before resampling for debugging/logging purposes (more on this later).

```cpp
template <size_t N>
struct MCL {
  float particle_x[N];
  float particle_y[N];
  float particle_weights[N];

  float temp_x[N];
  float temp_y[N];
  float temp_weights[N];

  float presample_x[N];
  float presample_y[N];
  float presample_weights[N];

  XorShift32 rng;

  MCL() : rng(pros::micros()) {
    std::fill(particle_x, particle_x + N, 0.0f);
    std::fill(particle_y, particle_y + N, 0.0f);
    std::fill(particle_weights, particle_weights + N, 1.0f / N);
    std::fill(temp_x, temp_x + N, 0.0f);
    std::fill(temp_y, temp_y + N, 0.0f);
    std::fill(temp_weights, temp_weights + N, 0.0f);
    std::fill(presample_x, presample_x + N, 0.0f);
    std::fill(presample_y, presample_y + N, 0.0f);
    std::fill(presample_weights, presample_weights + N, 0.0f);
  }
};
```

We'll also need to be able to capture the data about a distance sensor reading. The following struct captures a single sensor's actual reading, as well as information on its variance, relative position to the robot at a given heading, and a second point in the direction of the sensor's heading (used for raycasting later).

```cpp
struct Reading {
  float recorded;
  float inv_var;

  Point relative_pos;
  Point proj_relative;

  Reading(float recorded, float std_dev, Point relative_pos, Point proj_relative)
    : recorded(recorded),
      inv_var(-0.5f / (std_dev * std_dev)),
      relative_pos(relative_pos),
      proj_relative(proj_relative) {}
};
```

Note that we save the inverse variance multiplied by -0.5 to optimize the weight calculation later.

### Step 1: Initialization

Whenever you set the robot's position programatically, such as at the start of an autonomous routine, you should initialize the MCL particles around that position.

Additionally, you should seed your RNG based on the current system time to ensure a good random distribution.

```cpp
template <size_t N>
void MCL<N>::init(float x, float y, float spread) {
  rng = XorShift32(pros::micros());

  for (size_t i = 0; i < N; i++) {
    particle_x[i] = std::clamp(x + rng.range_f32(-spread, spread), FIELD_MIN, FIELD_MAX);
    particle_y[i] = std::clamp(y + rng.range_f32(-spread, spread), FIELD_MIN, FIELD_MAX);
    particle_weights[i] = 1.0f / N;
  }
}
```

A good value for spread is about 2 or 3 inches, because generally, you have a pretty good idea of where the bot starts of the field.

### Step 2: Prediction

Your odometry should be updating in a loop in your code, based on information from your motor encoders, IMU, and possible a odometry tracking wheel setup. After updating your odometry, you should call this prediction step (and the other following steps) to update your MCL particles. More information on using this MCL will come later.

There are two components to the prediction step: moving the particles based on odometry, and adding random noise to each particle.

```cpp
// step each particle but add some randomization as well
template <size_t N>
void MCL<N>::predict(float dx, float dy, float std_dev) {
  for (size_t i = 0; i < N; i++) {
    particle_x[i] += dx + rng.gaussian(std_dev);
    particle_y[i] += dy + rng.gaussian(std_dev);
    particle_x[i] = std::clamp(particle_x[i], FIELD_MIN, FIELD_MAX);
    particle_y[i] = std::clamp(particle_y[i], FIELD_MIN, FIELD_MAX);
  }
}
```

In this function, `dx` and `dy` are the changes in position according to your odometry since the last update. `std_dev` is the standard deviation of the noise to add to each particle. A good approximation for this will be found later.

### Step 3: Update

This is the core part of MCL. This step uses the distance sensor readings to update the weights of each particle.

First, however, we need to be able to predict what a distance sensor would read if the robot were at a given particle's position. This is done using raycasting. Because the field is a square, we can highly optimize the raycasting process.

We can define a `Line` to be a directed line segment from one point to another:

```cpp
struct Line {
  Point start;
  Point end;
};
```

For the distance sensor raycasting, we can treat a Line as an infinite ray starting at `start` and going through `end` instead of a line segment. This allows us to highly optimize the calculation of the intersection point between the ray and the field boundaries.

I won't get into the nitty gritty of exactly how this function works, but the key is that it returns the distance from the start of the ray to the intersection point with the field boundary. If there is no intersection, it returns `std::nullopt`.

```cpp
struct Line {
  Point start;
  Point end;

  // assumes line segments are actually rays
  inline std::optional<float> square_intersect_distance(float center_x, float center_y, float width, float height) const {
    float half_width = width * 0.5f;
    float half_height = height * 0.5f;

    float rel_start_x = start.x - center_x;
    float rel_start_y = start.y - center_y;

    float dx = end.x - start.x;
    float dy = end.y - start.y;

    float best_t = std::numeric_limits<float>::infinity();

    // check x sides
    if (std::abs(dx) > 1e-6f) {
      float inv_dx = 1.0f / dx;
      float target_x = dx > 0.0f ? half_width : -half_width;
      float t = (target_x - rel_start_x) * inv_dx;

      if (t >= 0.0f) {
        float y = rel_start_y + t * dy;
        if (std::abs(y) <= half_height) {
          best_t = t;
        }
      }
    }

    // check y sides
    if (std::abs(dy) > 1e-6f) {
      float inv_dy = 1.0f / dy;
      float target_y = dy > 0.0f ? half_height : -half_height;
      float t = (target_y - rel_start_y) * inv_dy;

      if (t >= 0.0f && t < best_t) {
        float x = rel_start_x + t * dx;
        if (std::abs(x) <= half_width) {
          best_t = t;
        }
      }
    }

    if (best_t < std::numeric_limits<float>::infinity()) {
      return best_t * std::hypot(dx, dy);
    }
    return std::nullopt;
  }
};
```

We can now add the following function to the `Reading` struct to predict what the distance sensor would read if the robot were at a given particle's position:

```cpp
// inside Reading struct:
inline std::optional<float> predict(Point particle_pos) const {
  return Line{relative_pos + particle_pos, proj_relative + particle_pos}
    .square_intersect_distance(0.0f, 0.0f, FIELD_SIZE, FIELD_SIZE);
}
```

Now that we have the raycasting set up, we can implement the update step.

Here's our function header:

```cpp
template <size_t N>
void MCL<N>::update(const std::vector<Reading>& readings) {
  float max_weight = 0.0f;
```

The first step is to loop over every particle and caluclate its weight. We start with a weight of 1.0 for each particle:

```cpp
for (size_t i = 0; i < N; i++) {
  float weight = 1.0f;
```

Then, for each distance sensor reading:

```cpp
for (const auto& reading : readings) {
```

We need to predict what the sensor would read if the robot were at this particle's position. If there is no intersection, we can set the weight to 0 and break out of the loop early.

```cpp
auto predicted = reading.predict(Point{particle_x[i], particle_y[i]});
if (predicted.has_value()) {
  // calculate weight
} else {
  weight = 0.0f;
  break;
}
```

To actually calculate the weight, we use the following formula:

```
error = recorded - predicted
w = e^(inv_var * error^2)
```

Where `recorded` is the actual distance sensor reading, `predicted` is the predicted reading for this particle, and `inv_var` is the inverse variance multiplied by -0.5 that we precomputed earlier.

This becomes:

```cpp
float error = reading.recorded - predicted.value();
weight *= std::exp(reading.inv_var * error * error);
if (weight == 0.0f) {
  break;
}
```

After weighting the particle, we do some final checks:

```cpp
if (!std::isfinite(weight) || weight < 0.0f) {
  weight = 0.0f;
}

particle_weights[i] = weight;
if (weight > max_weight) {
  max_weight = weight;
}
```

If you've been following along, you should have something akin to this:

```cpp
template <size_t N>
void MCL<N>::update(const std::vector<Reading>& readings) {
  float max_weight = 0.0f;

  // weight each particle
  for (size_t i = 0; i < N; i++) {
    float weight = 1.0f;

    for (const auto& reading : readings) {
      auto predicted = reading.predict(Point{particle_x[i], particle_y[i]});
      if (predicted.has_value()) {
        float error = reading.recorded - predicted.value();
        weight *= std::exp(reading.inv_var * error * error);
        if (weight == 0.0f) {
          break;
        }
      } else {
        weight = 0.0f;
        break;
      }
    }

    if (!std::isfinite(weight) || weight < 0.0f) {
      weight = 0.0f;
    }

    particle_weights[i] = weight;
    if (weight > max_weight) {
      max_weight = weight;
    }
  }
```

Lastly, we make sure we have weights that sum to 1.0 and then normalize them:

```cpp
  if (max_weight <= 0.0f) {
    // reset weights if all zero
    float uniform_weight = 1.0f / N;
    for (size_t i = 0; i < N; i++) {
      particle_weights[i] = uniform_weight;
    }

    return;
  }

  float weight_sum = 0.0f;
  for (size_t i = 0; i < N; i++) {
    particle_weights[i] /= max_weight;
    weight_sum += particle_weights[i];
  }

  if (weight_sum <= 0.0f) {
    // reset weights if all zero
    float uniform_weight = 1.0f / N;
    for (size_t i = 0; i < N; i++) {
      particle_weights[i] = uniform_weight;
    }

    return;
  }

  float inv_weight_sum = 1.0f / weight_sum;
  for (size_t i = 0; i < N; i++) {
    particle_weights[i] *= inv_weight_sum;
  }
}
```

### Step 4: Estimation

To get the estimated position of the robot, we simply calculate the weighted average of all the particles' positions:

```cpp
template <size_t N>
Point MCL<N>::estimate() const {
  float est_x = 0.0f;
  float est_y = 0.0f;

  for (size_t i = 0; i < N; i++) {
    est_x += particle_x[i] * particle_weights[i];
    est_y += particle_y[i] * particle_weights[i];
  }

  return Point{est_x, est_y};
}
```

### Step 5: Resampling

For resampling, we use a highly perfomant systematic sampling implementation.

To start, we save the current weights and positions of the particles for debugging/logging purposes:

```cpp
template <size_t N>
void MCL<N>::resample() {
  std::copy(particle_x, particle_x + N, presample_x);
  std::copy(particle_y, particle_y + N, presample_y);
  std::copy(particle_weights, particle_weights + N, presample_weights);
```

Our goal is to divide the range [0.0, 1.0] into N segments, where each segment corresponds to a particle and its weight. A higher weight means a larger segment. Think of it like making each particle a "bucket", and the size of the bucket is proportional to its weight.

We precalulate the reciprocal of N for optimization, and an initial random offset:

```cpp
float inv_n = 1.0f / N;
float offset = rng.next_f32() * inv_n;
```

We also need to keep track of the cumulative weight at the current index:

```cpp
float cumulative_weight = particle_weights[0];
size_t idx = 0;
```

For every particle;

```cpp
for (size_t i = 0; i < N; i++) {
```

Inside the loop, our goal is to drop a "pin" at intervals of `inv_n`, starting from `uniform_offset`, and see which particle's bucket it falls into. This means that particles with larger weights (bigger buckets) will have more "pins falling into them". In other words, they are more likely to be selected (possibly multiple times).

We first calculate the position of our sample:

```cpp
float sample = offset + i * inv_n;
```

We then find the index of the particle whose cumulative weight is just greater than or equal to our sample. This is done using a simple linear search:

```cpp
while (sample > cumulative_weight && idx < N - 1) {
  idx++;
  cumulative_weight += particle_weights[idx];
}
```

However, note that idx is NOT reset for each iteration of the outer loop. This means that our sampling is O(N) instead of O(N^2), because we only move forward through the cumulative weights array.

Finally, we assign the selected particle's position and new weight (which is just 1/N, because each particle is equally likely after resampling) to the temporary arrays:

```cpp
temp_x[i] = particle_x[std::min(idx, N - 1)];
temp_y[i] = particle_y[std::min(idx, N - 1)];
temp_weights[i] = inv_n;
```

Outside of the loop, we copy the temporary arrays back to the main particle arrays:

```cpp
std::copy(temp_x, temp_x + N, particle_x);
std::copy(temp_y, temp_y + N, particle_y);
std::copy(temp_weights, temp_weights + N, particle_weights);
```

The full resampling function now looks like this:

```cpp
template <size_t N>
void MCL<N>::resample() {
	std::copy(particle_x, particle_x + N, presample_x);
	std::copy(particle_y, particle_y + N, presample_y);
	std::copy(particle_weights, particle_weights + N, presample_weights);

	float inv_n = 1.0f / N;

	float offset = rng.next_f32() * inv_n;

	float cumulative_weight = particle_weights[0];
	size_t idx = 0;

	for (size_t i = 0; i < N; i++) {
		float sample = offset + i * inv_n;

		while (sample > cumulative_weight && idx < N - 1) {
			idx++;
			cumulative_weight += particle_weights[idx];
		}

		temp_x[i] = particle_x[idx];
		temp_y[i] = particle_y[idx];
		temp_weights[i] = inv_n;
	}

	std::copy(temp_x, temp_x + N, particle_x);
	std::copy(temp_y, temp_y + N, particle_y);
	std::copy(temp_weights, temp_weights + N, particle_weights);
}
```

## Usage

Now, the question is: how do I actually use this MCL effectively?

We need to call the four main steps (prediction, update, resample, estimate) in a loop immediately after your odometry updates.

Below is one way to implement this. Note that `dx` and `dy` are the changes in the robot's position according to your odometry since the last update.

### Step 1: Prediction

A good estimate for the standard deviation of the odometry updates is the hypotenuse of dy and dx divided by 4.0. The reasoning for this is beyond the scope of this guide, but generally, the more the robot moves, the less accurate the odometry is likely to be.

Additionally, **you may need to tune this value based on your robot and testing results.**

```cpp
mcl.predict(dx, dy, std::hypot(dx, dy) / 4.0f);
```

### Step 2: Get and process distance sensor readings:

This code will vary greatly based on how you handle distance sensors in your codebase. However, there are several general steps to follow:

1. Get the actual distance sensor readings from your sensors.
2. Filter the distance sensor readings. You can filter based on object size, distance, and of course drop sensors that don't have a valid reading. You can also check if the sensors are pointing at a match loader or goal (using the same method for checking the distance from the sensor to the wall), and drop those readings as well.
3. For each valid reading, create a `Reading` struct. You'll need to know the relative position of each sensor to the robot's center of rotation. Rotate each sensor's relative position using `x = x * cos(robot_theta)` and `y = y * sin(robot_theta)`. You'll also need to create a second point in the direction of the sensor's heading for raycasting. This will be at the relative position plus `(cos(sensor_theta + robot_theta), sin(sensor_theta + robot_theta))`.

Finally, to calculate the sensor's standard deviation, we use the information given from the VEX website:

> Below 200mm the accuracy is approximately +/‚Äê15mm, above 200mm the accuracy is approximately 5%.

This "accuracy" refers to 3 standard devations, so to get the standard deviation, we can use the following formula (which has been converted to inches):

```cpp
// d is in inches here
float d = sensor.get_distance();
float bound = d < 7.874015f ? 0.590551f : 0.05f * d;

const float K = 3.0f;
float std_dev = std::max(bound / K, 1e-6f);
```

This gives you the information you need to construct a `Reading` struct for each valid distance sensor reading.

Here's my implementation of this process, which also includes raycasting for field elements like the match loader and goal bases.

First, some field constants:

```cpp
// the distance from the center of the wall to the back center of the loader in inches
constexpr float LOADER_X = 47.0f;

// loader width / 2
constexpr float LOADER_RADIUS = 3.0f;

// padding to add to each side (except the back) of the loader for collision detection
constexpr float LOADER_PADDING = 0.5f;

constexpr float LOADER_WIDTH = LOADER_RADIUS * 2.0f + LOADER_PADDING * 2.0f;
constexpr float LOADER_LENGTH = LOADER_RADIUS * 2.0f + LOADER_PADDING;

// actual loader geo in (x, y)
constexpr std::array<std::pair<float, float>, 4> LOADERS = {{
  // bottom left
  {-LOADER_X, -(FIELD_SIZE / 2.0f) + LOADER_RADIUS + LOADER_PADDING / 2.0f},
  // top left
  {-LOADER_X,  (FIELD_SIZE / 2.0f) - LOADER_RADIUS - LOADER_PADDING / 2.0f},
  // top right
  { LOADER_X,  (FIELD_SIZE / 2.0f) - LOADER_RADIUS - LOADER_PADDING / 2.0f},
  // bottom right
  { LOADER_X, -(FIELD_SIZE / 2.0f) + LOADER_RADIUS + LOADER_PADDING / 2.0f},
}};

constexpr float GOAL_X = 48.0f;
constexpr float GOAL_Y = 23.0f;

constexpr float GOAL_PADDING = 1.0f;

constexpr float GOAL_WIDTH = 6.0f + GOAL_PADDING * 2.0f;
constexpr float GOAL_LENGTH = 3.0f + GOAL_PADDING * 2.0f;

constexpr std::array<std::pair<float, float>, 4> GOALS = {{
  // bottom left
  {-GOAL_X, -GOAL_Y},
  // top left
  {-GOAL_X,  GOAL_Y},
  // top right
  { GOAL_X,  GOAL_Y},
  // bottom right
  { GOAL_X, -GOAL_Y},
}};

constexpr float CENTER_PADDING = 1.0f;
constexpr float CENTER_WIDTH = 21.0f + CENTER_PADDING * 2.0f;
constexpr float CENTER_LENGTH = 21.0f + CENTER_PADDING * 2.0f;

constexpr std::pair<float, float> CENTER_POS = {0.0f, 0.0f};
```

Then, I use the existing line-square intersection algorithm to check if the sensor is pointing at any of the field elements, and if so, I drop the reading:

```cpp
std::vector<Reading> readings;

for (auto& sensor : sensors) {
  auto v = sensor.get();
  auto p = sensor.predict(pos);

  if (!v || !p) continue;
  if (std::abs(*v - *p) > mcl_tolerance) continue;

  Position relative_pos = sensor.offset.rotate(pos.theta);
  Point ray_pt = relative_pos.point() + Point{relative_pos.theta.cos(), relative_pos.theta.sin()};
  Line ray{relative_pos.point() + pos.point(), ray_pt + pos.point()};

  bool hits_obstacle =
    std::any_of(LOADERS.begin(), LOADERS.end(), [&](const auto& loader) {
      return ray.square_intersect_distance(loader.first, loader.second, LOADER_WIDTH, LOADER_LENGTH).has_value();
    }) ||
    std::any_of(GOALS.begin(), GOALS.end(), [&](const auto& goal) {
      return ray.square_intersect_distance(goal.first, goal.second, GOAL_WIDTH, GOAL_LENGTH).has_value();
    }) ||
    ray.square_intersect_distance(CENTER_POS.first, CENTER_POS.second, CENTER_WIDTH, CENTER_LENGTH).has_value();

  if (hits_obstacle) continue;

  float d = *v;
  float bound = d < 7.874015f ? 0.590551f : 0.05f * d;
  constexpr float K = 3.0f;
  float std_dev = std::max(bound / K, 1e-6f);

  readings.emplace_back(d, std_dev, relative_pos.point(), ray_pt);
}
```

## Step 2.5: Update

Now that you have a vector of `Reading` structs, you can call the update step:

```cpp
mcl.update(readings);
```

### Step 3: Estimate

Finally, you can get the estimated position of the robot and update your robot's position accordingly:

```cpp
Point estimated_pos = mcl.estimate();
robot.pos.x = estimated_pos.x;
robot.pos.y = estimated_pos.y;
```

### Step 4: Resample

After updating the weights, you can resample the particles:

```cpp
mcl.resample();
```

## Debugging and Tuning

For MCL to work effectively, you need to tune it properly. The best way to do this is to log the particle positions right before the resampling step onto an SD card and then visualize the point on your computer.

A couple notes on implementing this on the VEX V5 Brain side:

- Use 'append' mode when writing to the SD card: don't try and store the whole log in memory, or you will quickly run out of RAM.
- JSON or CSV are good formats for logging data.
- Read the `presample_x`, `presample_y`, and `presample_weights` arrays to get the particle data before resampling.
- Log the estimated position as well for reference and plotting.

Generally, if the particles aren't converging within the bounds of your robot relatively quickly, you might want to reduce odometry noise in the prediction step.
